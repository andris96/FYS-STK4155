
% Article                            Book
% 1. Name(s) of author(s)            1. Name(s) of author(s)   
% 2. Journal                         2. Title of book
% 3. Volume(boldface)                3. Publisher
% 4. Page                            4. Place and year
% 5. Year in parentheses             5. Eventual page numbers

@article{lectureNotes2024,
	title={Computational Physics, Lecture Notes Fall 2024},
	note={\url{https://compphysics.github.io/MachineLearning/doc/LectureNotes/_build/html/intro.html}},
	author={Morten Hjorth-Jensen},
	journal={Department of Physics, University of Oslo},
	year={2024},
	month={August}
}

@book{mml2020,
    author = {Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong},
    title = {Mathematics for Machine Learning},
    publisher = {Cambridge University Press},
    year ={2020},
    adress = {Cambridge, UK},
    pages= {158-159}
}


@book{Goodfellow2016,
    author={Ian Goodfellow, Yoshua Bengio and Aaron Courville},
    title={Deep Learning},
    publisher={MIT Press},
    year={2016},
    address= {Massachusetts},
    pages= {51-77}
}

% p. 80-95 gradient based optimization(4.3), constrained optimization(4.4), linear %least square(4.5) 
% Optimization for training deep models: 
% p. 290-296 basic algorithms(8.3).
% p. 296-302 parameter initialization strategies(8.4)
% p. 302-307 algorithm. with adaptive learning rates(8.5)
% p. 307-313 approximate 2nd order methods (8.6)



@book{raschka2022,    
    author = {Sebastian Raschka and Yuxi (Hayden) Liu and Vahid Mirjalili},      
    title = {Machine Learning with PyTorch and Scikit-Learn},  
    publisher = {Packt Publishing},
    year = {2022},
    address = {Birmingham, UK},
    pages= {105-137}
}
%____________Depending on what pages we used________________________
% p.105-137 preprocessing data
% p.171-185 best practices for evaluation and hyperparameter tuning
%p.53-76    logistic regression
%p.37-52    gradient optimization

@book{Hastie,
  author = {Trevor Hastie and Robert Tibshirani and Jerome Friedman},
  title = { The Elements of Statistical Learning | Data Mining, Inference, and Prediction},
  publisher = {Springer Science+Business Media},
  year = {2009},
  address = {New York, NY},
  pages = {223-225}
}

@book{bishop_2006_pattern,
  author = {Christopher M. Bishop},
  title = {Pattern Recognition and Machine Learning},
  publisher = {Springer Science+Business Media, LLC},
  year = {2006},
  address = {New York, NY}
}

% p. 101-119 logistic regression
% p. 223-225 bias variance tradeoff  
% p. 219-232 Ch.7.1-7.5 whole chapter about bias
% p. 241-249 cross-validation
% p. 249-254 bootstrap method


@article{scikit-learn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={ F. Pedregosa and G. Varoquaux and A. Gramfort and V. Micheland B. Thirion and O. Grisel and M. Blondel and P. Prettenhofer and R. Weiss and V. Dubourg and J. Vanderplas and and A. Passos and D.Cournapeau and M. Brucher and M. Perrot and E. Duchesnay},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

@book{lectureNotesRidge,
    author = {van Wieringen, W. N.},
    title = {lecture notes on ridge regression},
    publisher = {Creative Commons},
    year = {2023}
}

@conference{crossvalidation,
    author = {Kohavi, Ron},
    title = {A Study of Cross-Validation and Bootstrap
    for Accuracy Estimation and Model Selection},
    year = {1995},
    booktitle ={ International Joint Conference on Artificial Intelligence (IJCAI)}
}

%When using chatGPT make sure to save an extract and add it to 
%github
@misc{chatGPT,
  author       = {OpenAI ChatGPT},
  title        = {Response by ChatGPT, GPT-4},
  howpublished = {\url{https://chat.openai.com}},
  year         = {2024},
  note         = {Accessed: 2024-09-25}
}

