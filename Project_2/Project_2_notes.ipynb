{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes based on lectures and youtube video: https://www.youtube.com/watch?v=CqOfi41LfDw&ab_channel=StatQuestwithJoshStarmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal approximation theorem\n",
    "The great efficacy of neural networks can largely be contributed to the universal approximation theorem, which can simply be written as:\n",
    "\n",
    "$$\n",
    "\\vert F(\\boldsymbol{x})-f(\\boldsymbol{x};\\boldsymbol{\\Theta})\\vert < \\epsilon \\hspace{0.1cm} \\forall \\boldsymbol{x}\\in[0,1]^d.\n",
    "$$\n",
    "\n",
    "Where $F(\\boldsymbol{x})$ is a continuous function and deterministic function defined on the unit cube in $d$-dimensions, $F : [0,1]^d \\rightarrow \\mathbb{R} $. We aim to approximate $F$ for any given small positive error tolerance $\\epsilon > 0$. $f(\\boldsymbol{x}; \\boldsymbol{\\Theta})$ is a one-layer hidden neural network with parameters $\\boldsymbol{\\Theta} = (\\boldsymbol{W},\\boldsymbol{b})$ where the weights $\\boldsymbol{W}\\in\\mathbb{R}^{m\\times n}$ and the biases $\\boldsymbol{b}\\in \\mathbb{R}^{n}$. \n",
    "\n",
    "The neural network $f$ takes the input and computes for each neuron the value $\\boldsymbol{z_i}$ as: \n",
    "$$\\boldsymbol{z_i} = \\boldsymbol{w_i}\\cdot \\boldsymbol{x} + b_i$$\n",
    "Where $\\boldsymbol{w_i}$ and $b_i$ are the weight vector and bias for each neuron $i$. This value is then for each neuron passed through a continuous sigmoidal function $\\sigma(\\boldsymbol{z})$. Otherwise known as an activation function. This function has the property: \n",
    "$$\n",
    "\\sigma(\\boldsymbol{z}) = \\left\\{\\begin{array}{cc} 1 & \\boldsymbol{z}\\rightarrow \\infty\\\\ 0 & \\boldsymbol{z} \\rightarrow -\\infty \\end{array}\\right.\n",
    "$$\n",
    "Such a function could be for example the standard logistic function: \n",
    "$$ \\sigma(\\boldsymbol{z}) = \\frac{1}{1+\\mathrm e^{-\\boldsymbol{z}}} $$\n",
    "The function introduces non-linearity, which enables the possibility of approximating functions of high complexity.\n",
    "\n",
    "By summing the weighted outputs of all the neurons we approximate $F(\\boldsymbol{x})$. Specifically, if we denote each neuron's activated output as $\\sigma(z_i)$, then the final output of the neural network can be expressed as: \n",
    "$$f(\\boldsymbol{x}, \\boldsymbol{\\Theta}) = \\sum_{i=1}^{m}c_i \\sigma(z_i)$$\n",
    "Where $c_i$ are additional weights applied to each neuron's output in the summation. These weights allow the network to scale each neuron's contribution to the overall approximation. By adjusting the weights $\\boldsymbol{W}$, biases $\\boldsymbol{b}$, and the output weights $c_i$, we can tune $f(\\boldsymbol{x}; \\boldsymbol{\\Theta})$ to get as close as desired to $F(\\boldsymbol{x})$ within the given error tolerance $\\epsilon$.\n",
    "\n",
    "In single layer networks, the Universal Approximation Theorem guarantees that with the right weights, biases and number of neurons, we can approximate any continuous function. For multi-layer networks, which often enhance approximation power, backpropagation enables efficient tuning of parameters across layers through gradient descent methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back propagation\n",
    "Back propagation is a process in which we attempt to improve a neural network by adjusting the internal parameters through calculating gradients of the cost/loss function wrt these parameters. We examine the initial predictions of the network, and then work backwards from the output, adjusting each layer of neurons using the chain rule of calculus.\n",
    "\n",
    "### Forward pass\n",
    "First we do a forward pass, where we have an input that goes trough the network and predicts an output. \n",
    "\n",
    "### Error calculation\n",
    "We then use an cost/loss function such as MSE or Cross-Entropy Loss to evaluate how far off the target our prediction is. Our goal is to minimize the function.\n",
    "\n",
    "The MSE cost function is defined as:\n",
    "\n",
    "$$\n",
    "C(\\boldsymbol{\\Theta})=\\frac{1}{n}\\left\\{\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\theta}\\right)^T\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\theta}\\right)\\right\\}.\n",
    "$$\n",
    "\n",
    "Where $\\boldsymbol{\\Theta}$ represents all parameters in a neural network, which is given by the weights and biases.\n",
    "\n",
    "### Gradient calculation\n",
    "To adjust the weights and biases, we compute the gradient of the error function wrt each bias and weight. Some parameters contribute more to the error than others, which means that they need greater adjustments.\n",
    "\n",
    "### Gradient adjustment"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
