{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression and Classification problems\n",
    "In logistic regression we take a number of independant variables and try to determine the probability of a binary outcome in terms of true/false, positive/negative, ordered/disordered, spam/non-spam email, etc. We classify different input into one of the two categorized outputs using 0.5 as a cutoff.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization and Deep learning\n",
    "To make good predictions we want to minimize the cost function. We utilize minimization algorithms, with gradient descent methods as a subcategory of such algorithms.\n",
    "\n",
    "Linear regression models, can be used as classification, by converting $y_i \\leq 0.5$ to 0 and $y_i > 0.5$ to 1.\n",
    "\n",
    "In linear regression we work with continuous values of $y_i$, but in logistic regression we focus on descrete variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The standard Logistic function\n",
    "If we want to consider the probability that a given $x_i$ belongs to a category $y_i = {0,1}$, we can use the \"Sigmoid function\" or \"logit function\" which is expressed as: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(t) = \\frac{1}{1+\\mathrm e^{-t}}=\\frac{e^{t}}{1+e^{t}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $1-p(t) = p(-t)$. Where $t = \\beta_0 + \\beta_1 x_i$ in a simple linear standard linear regression with a linear dependance on x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have two classes where $y_i$ is equal to 0 or 1, we get the following:\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(y_i=1|x_i,\\boldsymbol{\\beta}) &= \\frac{e^{(\\beta_0+\\beta_1x_i)}}{1+e^{(\\beta_0+\\beta_1x_i)}},\\nonumber\\\\\n",
    "p(y_i=0|x_i,\\boldsymbol{\\beta}) &= 1 - p(y_i=1|x_i,\\boldsymbol{\\beta}),\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the total likelihood of a given dataset $\\mathcal{D}=\\{(y_i,x_i)\\}$, we have the likelihood function: \n",
    "$$\n",
    "\\begin{align*}\n",
    "P(\\mathcal{D}|\\boldsymbol{\\beta})& = \\prod_{i=1}^n \\left[p(y_i=1|x_i,\\boldsymbol{\\beta})\\right]^{y_i}\\left[1-p(y_i=1|x_i,\\boldsymbol{\\beta})\\right]^{1-y_i}\\nonumber \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "Which multiplies the probabilities for all the data points. It either multiplies the probabilities of class 1 or class 0. The goal is to find the $\\beta$s that maximises the probabilities. The log-likelihood or cost/loss function is derrived from the likelihood function:\n",
    "$$\n",
    "\\mathcal{C}(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left( y_i\\log{p(y_i=1|x_i,\\boldsymbol{\\beta})} + (1-y_i)\\log\\left[1-p(y_i=1|x_i,\\boldsymbol{\\beta}))\\right]\\right.\n",
    "$$\n",
    "This function is easier to work with since we go from product of probabilities to sums, making calculations simpler and more numerically stable. It can be rewritten as: \n",
    "$$\n",
    "\\mathcal{C}(\\boldsymbol{\\beta}) = \\sum_{i=1}^n  \\left(y_i(\\beta_0+\\beta_1x_i) -\\log{(1+\\exp{(\\beta_0+\\beta_1x_i)})}\\right).\n",
    "$$\n",
    "Where the cost function is just the negative log-likelihood function. The function is also called cross entropy in statistics. Minimizing with respect to $\\beta$ we get:\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{C}(\\boldsymbol{\\beta})}{\\partial \\beta_0} = -\\sum_{i=1}^n  \\left(y_i -\\frac{\\exp{(\\beta_0+\\beta_1x_i)}}{1+\\exp{(\\beta_0+\\beta_1x_i)}}\\right),\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{C}(\\boldsymbol{\\beta})}{\\partial \\beta_1} = -\\sum_{i=1}^n  \\left(y_ix_i -x_i\\frac{\\exp{(\\beta_0+\\beta_1x_i)}}{1+\\exp{(\\beta_0+\\beta_1x_i)}}\\right).\n",
    "$$\n",
    "A compact expression with vector $\\boldsymbol{y}$ with $n$ elements $y_i$, an\n",
    "$n\\times p$ matrix $\\boldsymbol{X}$ which contains the $x_i$ values and a\n",
    "vector $\\boldsymbol{p}$ of fitted probabilities $p(y_i\\vert x_i,\\boldsymbol{\\beta})$. We get:\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{C}(\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} = -\\boldsymbol{X}^T\\left(\\boldsymbol{y}-\\boldsymbol{p}\\right).\n",
    "$$\n",
    "If we in addition define a diagonal matrix $\\boldsymbol{W}$ with elements \n",
    "$p(y_i\\vert x_i,\\boldsymbol{\\beta})(1-p(y_i\\vert x_i,\\boldsymbol{\\beta}))$, we can obtain a compact expression of the second derivative as\n",
    "$$\n",
    "\\frac{\\partial^2 \\mathcal{C}(\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}\\partial \\boldsymbol{\\beta}^T} = \\boldsymbol{X}^T\\boldsymbol{W}\\boldsymbol{X}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having $p$ predictors leads to the terms looking like: $\\beta_0+\\beta_1x_1+\\beta_2x_2+\\dots+\\beta_px_p$ and:\n",
    "$$\n",
    "\\log{ \\frac{p(\\boldsymbol{\\beta}\\boldsymbol{x})}{1-p(\\boldsymbol{\\beta}\\boldsymbol{x})}} = \\beta_0+\\beta_1x_1+\\beta_2x_2+\\dots+\\beta_px_p.\n",
    "$$\n",
    "leading to:\n",
    "$$\n",
    "p(\\boldsymbol{\\beta}\\boldsymbol{x})=\\frac{ \\exp{(\\beta_0+\\beta_1x_1+\\beta_2x_2+\\dots+\\beta_px_p)}}{1+\\exp{(\\beta_0+\\beta_1x_1+\\beta_2x_2+\\dots+\\beta_px_p)}}.\n",
    "$$\n",
    "Leading to more columns in matrix $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More classes with 2 predictors gives:\n",
    "$$\n",
    "\\log{\\frac{p(C=1\\vert x)}{p(K\\vert x)}} = \\beta_{10}+\\beta_{11}x_1,\n",
    "$$\n",
    "and \n",
    "$$\n",
    "\\log{\\frac{p(C=2\\vert x)}{p(K\\vert x)}} = \\beta_{20}+\\beta_{21}x_1,\n",
    "$$\n",
    "and so on till the class $C=K-1$ class\n",
    "$$\n",
    "\\log{\\frac{p(C=K-1\\vert x)}{p(K\\vert x)}} = \\beta_{(K-1)0}+\\beta_{(K-1)1}x_1,\n",
    "$$\n",
    "The $\\beta$ vector would then become a matrix. With $k-1$ rows and $p$ columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In neural networks we use a slightly modified version, called the Softmax function:\n",
    "$$\n",
    "p(C=k\\vert \\mathbf {x} )=\\frac{\\exp{(\\beta_{k0}+\\beta_{k1}x_1)}}{1+\\sum_{l=1}^{K-1}\\exp{(\\beta_{l0}+\\beta_{l1}x_1)}}.\n",
    "$$\n",
    "and the final class:\n",
    "$$\n",
    "p(C=K\\vert \\mathbf {x} )=\\frac{1}{1+\\sum_{l=1}^{K-1}\\exp{(\\beta_{l0}+\\beta_{l1}x_1)}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "$$\n",
    "\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\gamma_k \\nabla F(\\mathbf{x}_k),\n",
    "$$\n",
    "$\\gamma_k$ is step length or \"learning rate\". Can find a local minima, in the case of a convex function we find global minima. Multiple local minima can pose a problem for this method. It is sensitive to initial conditions. The gradient is a function of $X$ which makes it expensive to compute numerically. The optimal step size can be important to find. Too large step size will lead to us getting past the local minima and create problems for finding it precisely. Too small stepsize will make for heavy computation.\n",
    "\n",
    "If the function is convex, any local minima is also global minima. This is important to know when minimizing cost/loss functions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD)\n",
    "Stochastic Gradient Descent (SGD) introduces randomness to help escape local minima and improve convergence. Instead of using the entire dataset to compute the gradient, SGD updates the model parameters using the gradient of a single data point or a small subset of data points (mini-batch). This introduces noise into the gradient updates, which can help the algorithm to explore the parameter space more effectively. The gradient of the total dataset is the sum of the gradients of each individual data point, but in practice, we approximate this by summing the gradients of the mini-batches. SGD can be more efficient because it computes the gradient using fewer data points at a time, but does so more frequently. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
